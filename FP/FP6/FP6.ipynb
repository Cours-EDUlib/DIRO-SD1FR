{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FP6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3q72u9kfOO_"
      },
      "source": [
        "# Formation Pratique 6 : k-NN, sklearn et arbres de décision\n",
        "\n",
        "Dans cette formation pratique, nous allons entrainer et tester nos premiers modèles de machine learning sur le jeu de données *Adult*, qui a été présenté et étudié lors de la Formation Pratique 2.\n",
        "\n",
        "On commencera par séparer les données d'entrainement et de test avec la librairie *scikit-learn*, et faire notre propre implémentation de l'algorithme des k plus proches voisins. Enfin, nous utiliserons *scikit-learn* pour très facilement deployer un modèle de foret d'arbres de décision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qNRzsYsgnfu"
      },
      "source": [
        "## 6.1 Séparation des données d'entrainement et de test\n",
        "\n",
        "Commençons par charger le dataset *Adult* avec pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "n4QqCaf5acam",
        "outputId": "14eecfc6-04da-47a9-d900-a947e867e094"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "!wget -nc https://raw.githubusercontent.com/Cours-EDUlib/DIRO-SD1FR/master/FP/FP2/adult.csv\n",
        "\n",
        "df = pd.read_csv(\"adult.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘adult.csv’ already there; not retrieving.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>educational-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>Private</td>\n",
              "      <td>226802</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>89814</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Farming-fishing</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>Local-gov</td>\n",
              "      <td>336951</td>\n",
              "      <td>Assoc-acdm</td>\n",
              "      <td>12</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Protective-serv</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44</td>\n",
              "      <td>Private</td>\n",
              "      <td>160323</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>7688</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18</td>\n",
              "      <td>?</td>\n",
              "      <td>103497</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>?</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  workclass  fnlwgt  ... hours-per-week  native-country income\n",
              "0   25    Private  226802  ...             40   United-States  <=50K\n",
              "1   38    Private   89814  ...             50   United-States  <=50K\n",
              "2   28  Local-gov  336951  ...             40   United-States   >50K\n",
              "3   44    Private  160323  ...             40   United-States   >50K\n",
              "4   18          ?  103497  ...             30   United-States  <=50K\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Jhd3c5dhFmQ"
      },
      "source": [
        "On ne garde que les colonnes avec des valeurs numériques (par soucis de simplicité), et on sépare la variable que l'on cherche à prédire (*income*) des variables dont nous nous servirons comme entrée"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7bF7L5ghOLo"
      },
      "source": [
        "cts_columns = ['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
        "y = np.array(df['income'])\n",
        "X = np.array(df[cts_columns])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZL6ZgUsDheKr"
      },
      "source": [
        "À présent, nous pouvons séparer les données d'entrainement et de test. Dans le cadre de cette FP, nous n'utiliserons pas de données de validation, par soucis de simplicité. L'utilisation d'un jeu de données de validation sera abordé dans la Formation Pratique 7.\n",
        "\n",
        "Pour cela, la très utile librairie *scikit-learn* dispose d'une méthode très simple d'utilisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk6t1KGRhGWO"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gA5P89zIiyS4"
      },
      "source": [
        "Nous avons séparé notre jeu de données entre entrainement (80% des données) et test (20% des données). Le but est d'entrainer un modèle à prédire **y_train** en utilisant l'information de **X_train**, en espérant que le modèle ainsi entrainé puisse efficacement prédire **y_test** à partir de **X_test**, bien qu'aucun de ces points de tests n'ai été observé à l'entrainement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fkn5LFK4m2wK"
      },
      "source": [
        "## 6.2 k plus proches voisins\n",
        "\n",
        "Dans cette section, nous allons implémenter la méthode des k plus proches voisins. Pour rappel, le principe de cette méthode est le suivant : étant donné un point d'entrée x et un entier k, on trouve les k points du jeu de données d'entrainement les plus proches de x $[x_0, x_1, ..., x_k]$, puis on retourne comme prédiction la classe majoritaire parmis $[y_0, y_1, ..., y_k]$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5idaqL9oHf6"
      },
      "source": [
        "## 6.2.1 Implémentation : \n",
        "Nous allons definir une classe **MyKNN**, avec une méthode pour instancier la classe (*init*), une méthode pour l'entrainement (*fit*, qui consiste juste à mémoriser le jeu de données d'entrainement dans le cas de k plus proches voisins), une méthode pour calculer la distance euclidienne entre deux points (*calculate_euclidean*), une méthode pour calculer les k plus proches voisins d'un point (*nearest_neighbors*), et enfin une méthode pour effectuer les prédictions sur un ensemble de points (*predict*).\n",
        "\n",
        "**Question** : Compléter les méthodes *nearest_neighbors* et *predict* dans la cellule de code suivante, en suivant les instructions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2DpgzsqoRUQ"
      },
      "source": [
        "class MyKNN():\n",
        "  def __init__(self, k):\n",
        "    # Cette méthode instancie la classe et sauvegarde 'k'. Rien à modifier.\n",
        "    self.k=k\n",
        "\n",
        "  def fit(self, X_train, y_train):\n",
        "    # Pour entrainer k plus proches voisins, on sauvegarde simplement les données d'entrainement. Rien à modifier.\n",
        "    self.X_train = X_train\n",
        "    self.y_train = y_train\n",
        "\n",
        "  def calculate_euclidean(self, x1, x2):\n",
        "    # On se sert ici de numpy pour calculer la distance euclidienne entre deux points. Rien à modifier.\n",
        "    return np.linalg.norm(x1-x2)\n",
        "\n",
        "  def nearest_neighbors(self, x_test):\n",
        "    # On cherche maintenant à calculer les k points de self.X_train les plus proches du point x_test\n",
        "\n",
        "    distances = [] # TODO : utiliser la methode self.calculate_euclidean pour calculer les distances entre x_test et chaque point de self.X_train\n",
        "                   # distances[i] doit retourner la distance euclidienne entre x_test et self.X_train[i]\n",
        "\n",
        "    distance_idx = list(enumerate(distances)) # On obtient une liste des paires [(distance0, 0), (distance1, 1), ...]\n",
        "    distance_idx.sort(key=lambda x:x[0]) # On tri distance_idx par ordre croissant de distance\n",
        "\n",
        "    neighbors = [] # TODO : utiliser distance_idx pour extraire les indices des k plus proches voisins de x_test, et les stocker dans neighbors\n",
        "\n",
        "    return neighbors\n",
        "    \n",
        "  def predict(self, test_set):\n",
        "    # Enfin, pour un ensemble de points test_set, on cherche à calculer les predictions de k plus proche voisin sur chaque point\n",
        "    predictions = []\n",
        "\n",
        "    for test_sample in test_set:\n",
        "      neighbors = self.nearest_neighbors(test_sample) # indices des k plus proches voisins\n",
        "\n",
        "      prediction = 0 # TODO : Calculer la prediction du point test_sample en utilisant neighbors\n",
        "\n",
        "      predictions.append(prediction)\n",
        "\n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qp-xzmKDoPBy"
      },
      "source": [
        "#### Réponses (essayez d'abord de répondre par vous-même avant de regarder la réponse)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBGiS_aqoRqq"
      },
      "source": [
        "class MyKNN():\n",
        "  def __init__(self, k):\n",
        "    # Cette méthode instancie la classe et sauvegarde 'k'. Rien à modifier.\n",
        "    self.k=k\n",
        "\n",
        "  def fit(self, X_train, y_train):\n",
        "    # Pour entrainer k plus proches voisins, on sauvegarde simplement les données d'entrainement. Rien à modifier.\n",
        "    self.X_train = X_train\n",
        "    self.y_train = y_train\n",
        "\n",
        "  def calculate_euclidean(self, x1, x2):\n",
        "    # On se sert ici de numpy pour calculer la distance euclidienne entre deux points. Rien à modifier.\n",
        "    return np.linalg.norm(x1 - x2)\n",
        "\n",
        "  def nearest_neighbors(self, x_test):\n",
        "    # On cherche maintenant à calculer les k points de self.X_train les plus proches du point x_test\n",
        "\n",
        "    distances = [self.calculate_euclidean(x_test, x_train) for x_train in self.X_train]\n",
        "\n",
        "    distance_idx = list(enumerate(distances)) # On obtient une liste des paires [(0, distance0), (1, distance1), ...]\n",
        "    distance_idx.sort(key=lambda x:x[1]) # On tri distance_idx par ordre croissant de distance\n",
        "\n",
        "    neighbors = [x[0] for x in distance_idx[:self.k]] \n",
        "    \n",
        "    return neighbors\n",
        "    \n",
        "  def predict(self, test_set):\n",
        "    # Enfin, pour un ensemble de points test_set, on cherche à calculer les predictions de k plus proche voisin sur chaque point\n",
        "    predictions = []\n",
        "\n",
        "    for test_sample in test_set:\n",
        "      neighbors = self.nearest_neighbors(test_sample) # indices des k plus proches voisins\n",
        "\n",
        "      counter = 0 # we count how many '<=50K' classes are in the neighbors\n",
        "      for idx in neighbors:\n",
        "        if self.y_train[idx] == '<=50K':\n",
        "          counter += 1\n",
        "      if counter >= (len(neighbors) / 2.):\n",
        "        prediction = '<=50K'\n",
        "      else:\n",
        "        prediction = '>50K'\n",
        "    # Note : there are simpler ways to count the classes, but this one uses the most basic tools\n",
        "\n",
        "      predictions.append(prediction)\n",
        "\n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-JlBqtH_RvV"
      },
      "source": [
        "### 6.2.2 Performance\n",
        "\n",
        "On peut à présent tester notre implémentation et en mesurer la precision sur les 50 premiers points d'entrainement de l'ensemble d'entrainement et les 50 premiers élements de l'ensemble de test :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BKT85eP_fGa",
        "outputId": "e629528f-2e6f-4dc0-ce34-5ba68312196f"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model = MyKNN(k=1)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_test = model.predict(X_test[:50])\n",
        "y_pred_train = model.predict(X_train[:50])\n",
        "\n",
        "score_train = accuracy_score(y_pred_train, y_train[:50])\n",
        "score_test = accuracy_score(y_pred_test, y_test[:50])\n",
        "print('train score : {}'.format(score_train))\n",
        "print('test score : {}'.format(score_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train score : 1.0\n",
            "test score : 0.74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdxbhMjCHlP8"
      },
      "source": [
        "**Question** : on observe que la precision sur les 50 premiers points d'entrainement est de 100% avec k=1. Est-ce attendu ? Si on augmente le nombre de points, la précision restera-t-elle de 100% ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1diyJtTICXf"
      },
      "source": [
        "#### Réponses (essayez d'abord de répondre par vous-même avant de regarder la réponse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvS6lNPPIDn2"
      },
      "source": [
        "Avec k=1, si on effectue la prédiction sur un point d'entrainement, alors son plus proche voisin sera nécessairement lui-même, et on lui affectera donc toujours sa classe dans le jeu d'entrainement. On s'attends donc à toujours avoir une précision de 100% sur le jeu d'entrainement quand k=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYeXOOsmIX29"
      },
      "source": [
        "### 6.2.3 Temps de calcul, implémentation sklearn et choix de k\n",
        "\n",
        "Vous avez sans doute remarqué qu'effectuer les prédictions pour 50 points d'entrainement et 50 points de test n'était pas très rapide. En effet, le temps d'execution de k plus proche voisin augmente avec la taille du jeu de données d'entrainement (ici environ 39,000 points). Cependant, c'est avant tout car notre implémentation est très naive. Utilisons maintenant l'implémentation de scikit-learn qui est optimisée, et comparons les performances pour différentes valeurs de k."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "luAyPb7FJB1P",
        "outputId": "2b70b677-559c-4912-b44a-5ff8edd1b564"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn import neighbors\n",
        "\n",
        "score_test = []\n",
        "k_val = [1, 2, 3, 5, 10, 20]\n",
        "for k in k_val:\n",
        "    clf = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
        "    clf.fit(X_train, y_train)\n",
        "    score_test.append(clf.score(X_test, y_test))\n",
        "\n",
        "plt.plot(k_val, score_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8031225850>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QB0blfRJ3Qk"
      },
      "source": [
        "On remarque que l'implémentation de sklearn est considérablement plus rapide que notre implémentation naive. La courbe tracée précédement nous montre les performances pour différentes valeurs de l'hyperparamètre k. Nous traiterons plus en détail dans la prochaine Formation Pratique 7 le choix des hyperparamètres."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rWNVW7TKM2-"
      },
      "source": [
        "## 6.3 Arbres de décision\n",
        "\n",
        "Les arbres décisionnels sont des méthodes de classification. Chaque noeud de l'arbre représente une condition sur une variable. Lorsque l'on construit l'arbre, on cherche d'abord à sélectionner les variables qui permettent le mieux de séparer nos données en deux groupes selon un certain critère (ex. entropie de Shannon, Gini). Un grand avantage des arbres décisionnels, c'est qu'il est généralement très facile d'interpréter les décisions de ces modèles. Appliquons un arbre décisionnel implémenté dans scikit-learn sur nos données:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaVht9ioLAGc",
        "outputId": "a15a1732-74d9-42cd-a910-5131bef3cbee"
      },
      "source": [
        "from sklearn import tree\n",
        "\n",
        "clf = tree.DecisionTreeClassifier(criterion='gini', max_depth=3)\n",
        "clf = clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8057119459514792"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dNRj0gQMMmu"
      },
      "source": [
        "Avec sklearn, on peut ainsi entrainer un arbre et le tester en seulement 3 lignes !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMHm-bP9LE1G"
      },
      "source": [
        "Maintenant, grâce au module graphviz nous pouvons visualiser l'arbre de décision qui a été construit (pour installer graphviz: pip install graphviz)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "WyYsrwYMLGu_",
        "outputId": "8169499f-d99c-429d-e23f-6bf17fbb7462"
      },
      "source": [
        "import graphviz\n",
        "dot_data = tree.export_graphviz(clf, out_file=None, \n",
        "                         feature_names=cts_columns,   \n",
        "                         filled=True, rounded=True,  \n",
        "                         special_characters=True) \n",
        "\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f802e7f8710>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"1194pt\" height=\"373pt\"\n viewBox=\"0.00 0.00 1193.50 373.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 369)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-369 1189.5,-369 1189.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#eda977\" stroke=\"#000000\" d=\"M702,-365C702,-365 569,-365 569,-365 563,-365 557,-359 557,-353 557,-353 557,-309 557,-309 557,-303 563,-297 569,-297 569,-297 702,-297 702,-297 708,-297 714,-303 714,-309 714,-309 714,-353 714,-353 714,-359 708,-365 702,-365\"/>\n<text text-anchor=\"start\" x=\"568\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">capital&#45;gain ≤ 5119.0</text>\n<text text-anchor=\"start\" x=\"597.5\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.364</text>\n<text text-anchor=\"start\" x=\"579.5\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 39073</text>\n<text text-anchor=\"start\" x=\"565\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [29724, 9349]</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#eca16c\" stroke=\"#000000\" d=\"M553.5,-261C553.5,-261 409.5,-261 409.5,-261 403.5,-261 397.5,-255 397.5,-249 397.5,-249 397.5,-205 397.5,-205 397.5,-199 403.5,-193 409.5,-193 409.5,-193 553.5,-193 553.5,-193 559.5,-193 565.5,-199 565.5,-205 565.5,-205 565.5,-249 565.5,-249 565.5,-255 559.5,-261 553.5,-261\"/>\n<text text-anchor=\"start\" x=\"405.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">educational&#45;num ≤ 12.5</text>\n<text text-anchor=\"start\" x=\"443.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.325</text>\n<text text-anchor=\"start\" x=\"425.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 37222</text>\n<text text-anchor=\"start\" x=\"411\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [29622, 7600]</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M585.0746,-296.9465C570.8488,-287.3395 555.2437,-276.8009 540.5602,-266.8848\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"542.2847,-263.8261 532.0386,-261.13 538.3671,-269.6272 542.2847,-263.8261\"/>\n<text text-anchor=\"middle\" x=\"536.7951\" y=\"-281.9733\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#45a3e7\" stroke=\"#000000\" d=\"M839,-261C839,-261 712,-261 712,-261 706,-261 700,-255 700,-249 700,-249 700,-205 700,-205 700,-199 706,-193 712,-193 712,-193 839,-193 839,-193 845,-193 851,-199 851,-205 851,-205 851,-249 851,-249 851,-255 845,-261 839,-261\"/>\n<text text-anchor=\"start\" x=\"708\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">capital&#45;gain ≤ 7055.5</text>\n<text text-anchor=\"start\" x=\"737.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.104</text>\n<text text-anchor=\"start\" x=\"723.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1851</text>\n<text text-anchor=\"start\" x=\"713.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [102, 1749]</text>\n</g>\n<!-- 0&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>0&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M681.3412,-296.9465C694.1529,-287.4293 708.1952,-276.9978 721.4344,-267.163\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"723.6155,-269.9029 729.5558,-261.13 719.4412,-264.2837 723.6155,-269.9029\"/>\n<text text-anchor=\"middle\" x=\"725.9068\" y=\"-282.1623\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#e99559\" stroke=\"#000000\" d=\"M312,-157C312,-157 179,-157 179,-157 173,-157 167,-151 167,-145 167,-145 167,-101 167,-101 167,-95 173,-89 179,-89 179,-89 312,-89 312,-89 318,-89 324,-95 324,-101 324,-101 324,-145 324,-145 324,-151 318,-157 312,-157\"/>\n<text text-anchor=\"start\" x=\"211\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">age ≤ 30.5</text>\n<text text-anchor=\"start\" x=\"207.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.239</text>\n<text text-anchor=\"start\" x=\"189.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 28594</text>\n<text text-anchor=\"start\" x=\"175\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [24629, 3965]</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M404.2248,-192.9465C381.2017,-182.8008 355.8212,-171.6161 332.2364,-161.2228\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"333.5111,-157.9598 322.9488,-157.13 330.6883,-164.3654 333.5111,-157.9598\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#f8ddc9\" stroke=\"#000000\" d=\"M544,-157C544,-157 419,-157 419,-157 413,-157 407,-151 407,-145 407,-145 407,-101 407,-101 407,-95 413,-89 419,-89 419,-89 544,-89 544,-89 550,-89 556,-95 556,-101 556,-101 556,-145 556,-145 556,-151 550,-157 544,-157\"/>\n<text text-anchor=\"start\" x=\"447\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">age ≤ 29.5</text>\n<text text-anchor=\"start\" x=\"443.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.488</text>\n<text text-anchor=\"start\" x=\"429.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 8628</text>\n<text text-anchor=\"start\" x=\"415\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [4993, 3635]</text>\n</g>\n<!-- 1&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>1&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M481.5,-192.9465C481.5,-184.776 481.5,-175.9318 481.5,-167.3697\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"485.0001,-167.13 481.5,-157.13 478.0001,-167.13 485.0001,-167.13\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#e68540\" stroke=\"#000000\" d=\"M137,-53C137,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,0 12,0 12,0 137,0 137,0 143,0 149,-6 149,-12 149,-12 149,-41 149,-41 149,-47 143,-53 137,-53\"/>\n<text text-anchor=\"start\" x=\"36.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.065</text>\n<text text-anchor=\"start\" x=\"18.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 10367</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [10018, 349]</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M185.2118,-88.9777C167.4432,-78.9504 148.0792,-68.0228 130.5859,-58.1508\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"132.0561,-54.9616 121.6269,-53.095 128.6157,-61.0579 132.0561,-54.9616\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#eba06a\" stroke=\"#000000\" d=\"M312,-53C312,-53 179,-53 179,-53 173,-53 167,-47 167,-41 167,-41 167,-12 167,-12 167,-6 173,0 179,0 179,0 312,0 312,0 318,0 324,-6 324,-12 324,-12 324,-41 324,-41 324,-47 318,-53 312,-53\"/>\n<text text-anchor=\"start\" x=\"207.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.318</text>\n<text text-anchor=\"start\" x=\"189.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 18227</text>\n<text text-anchor=\"start\" x=\"175\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [14611, 3616]</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M245.5,-88.9777C245.5,-80.7364 245.5,-71.887 245.5,-63.5153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"249.0001,-63.2484 245.5,-53.2485 242.0001,-63.2485 249.0001,-63.2484\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#e99355\" stroke=\"#000000\" d=\"M470.5,-53C470.5,-53 354.5,-53 354.5,-53 348.5,-53 342.5,-47 342.5,-41 342.5,-41 342.5,-12 342.5,-12 342.5,-6 348.5,0 354.5,0 354.5,0 470.5,0 470.5,0 476.5,0 482.5,-6 482.5,-12 482.5,-12 482.5,-41 482.5,-41 482.5,-47 476.5,-53 470.5,-53\"/>\n<text text-anchor=\"start\" x=\"374.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.216</text>\n<text text-anchor=\"start\" x=\"360.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1895</text>\n<text text-anchor=\"start\" x=\"350.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1662, 233]</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M457.1732,-88.9777C450.8221,-80.0954 443.966,-70.5067 437.5768,-61.5711\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"440.2893,-59.3472 431.6259,-53.2485 434.5952,-63.4187 440.2893,-59.3472\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#fbfdfe\" stroke=\"#000000\" d=\"M638,-53C638,-53 513,-53 513,-53 507,-53 501,-47 501,-41 501,-41 501,-12 501,-12 501,-6 507,0 513,0 513,0 638,0 638,0 644,0 650,-6 650,-12 650,-12 650,-41 650,-41 650,-47 644,-53 638,-53\"/>\n<text text-anchor=\"start\" x=\"546\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"523.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6733</text>\n<text text-anchor=\"start\" x=\"509\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [3331, 3402]</text>\n</g>\n<!-- 5&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M514.6409,-88.9777C523.6498,-79.7292 533.4048,-69.7147 542.4109,-60.4691\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"544.9739,-62.8539 549.4445,-53.2485 539.9596,-57.9696 544.9739,-62.8539\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<path fill=\"#aed7f4\" stroke=\"#000000\" d=\"M839,-157C839,-157 712,-157 712,-157 706,-157 700,-151 700,-145 700,-145 700,-101 700,-101 700,-95 706,-89 712,-89 712,-89 839,-89 839,-89 845,-89 851,-95 851,-101 851,-101 851,-145 851,-145 851,-151 845,-157 839,-157\"/>\n<text text-anchor=\"start\" x=\"708\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">capital&#45;gain ≤ 5316.5</text>\n<text text-anchor=\"start\" x=\"737.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.467</text>\n<text text-anchor=\"start\" x=\"727.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 218</text>\n<text text-anchor=\"start\" x=\"721.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [81, 137]</text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M775.5,-192.9465C775.5,-184.776 775.5,-175.9318 775.5,-167.3697\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"779.0001,-167.13 775.5,-157.13 772.0001,-167.13 779.0001,-167.13\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<path fill=\"#3c9ee5\" stroke=\"#000000\" d=\"M1039.5,-157C1039.5,-157 931.5,-157 931.5,-157 925.5,-157 919.5,-151 919.5,-145 919.5,-145 919.5,-101 919.5,-101 919.5,-95 925.5,-89 931.5,-89 931.5,-89 1039.5,-89 1039.5,-89 1045.5,-89 1051.5,-95 1051.5,-101 1051.5,-101 1051.5,-145 1051.5,-145 1051.5,-151 1045.5,-157 1039.5,-157\"/>\n<text text-anchor=\"start\" x=\"951\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">age ≤ 20.5</text>\n<text text-anchor=\"start\" x=\"947.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.025</text>\n<text text-anchor=\"start\" x=\"933.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1633</text>\n<text text-anchor=\"start\" x=\"927.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [21, 1612]</text>\n</g>\n<!-- 8&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>8&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M844.2619,-192.9465C865.4045,-182.4759 888.7814,-170.8987 910.3304,-160.2268\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"912.034,-163.2889 919.4419,-155.7145 908.9273,-157.016 912.034,-163.2889\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M771.5,-53C771.5,-53 679.5,-53 679.5,-53 673.5,-53 667.5,-47 667.5,-41 667.5,-41 667.5,-12 667.5,-12 667.5,-6 673.5,0 679.5,0 679.5,0 771.5,0 771.5,0 777.5,0 783.5,-6 783.5,-12 783.5,-12 783.5,-41 783.5,-41 783.5,-47 777.5,-53 771.5,-53\"/>\n<text text-anchor=\"start\" x=\"696\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"677.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 110</text>\n<text text-anchor=\"start\" x=\"675.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 110]</text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>9&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M757.8719,-88.9777C753.412,-80.3702 748.6084,-71.0992 744.1021,-62.402\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"747.0675,-60.5172 739.3593,-53.2485 740.8522,-63.7376 747.0675,-60.5172\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<path fill=\"#eeab7b\" stroke=\"#000000\" d=\"M905.5,-53C905.5,-53 813.5,-53 813.5,-53 807.5,-53 801.5,-47 801.5,-41 801.5,-41 801.5,-12 801.5,-12 801.5,-6 807.5,0 813.5,0 813.5,0 905.5,0 905.5,0 911.5,0 917.5,-6 917.5,-12 917.5,-12 917.5,-41 917.5,-41 917.5,-47 911.5,-53 905.5,-53\"/>\n<text text-anchor=\"start\" x=\"821.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"811.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 108</text>\n<text text-anchor=\"start\" x=\"809.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [81, 27]</text>\n</g>\n<!-- 9&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>9&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M805.1153,-88.9777C813.0064,-79.9123 821.5381,-70.111 829.4522,-61.0192\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"832.2906,-63.0892 836.2164,-53.2485 827.0107,-58.4932 832.2906,-63.0892\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<path fill=\"#efb388\" stroke=\"#000000\" d=\"M1023,-53C1023,-53 948,-53 948,-53 942,-53 936,-47 936,-41 936,-41 936,-12 936,-12 936,-6 942,0 948,0 948,0 1023,0 1023,0 1029,0 1035,-6 1035,-12 1035,-12 1035,-41 1035,-41 1035,-47 1029,-53 1023,-53\"/>\n<text text-anchor=\"start\" x=\"947.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.408</text>\n<text text-anchor=\"start\" x=\"946\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 7</text>\n<text text-anchor=\"start\" x=\"944\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [5, 2]</text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M985.5,-88.9777C985.5,-80.7364 985.5,-71.887 985.5,-63.5153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"989.0001,-63.2484 985.5,-53.2485 982.0001,-63.2485 989.0001,-63.2484\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<path fill=\"#3b9ee5\" stroke=\"#000000\" d=\"M1173.5,-53C1173.5,-53 1065.5,-53 1065.5,-53 1059.5,-53 1053.5,-47 1053.5,-41 1053.5,-41 1053.5,-12 1053.5,-12 1053.5,-6 1059.5,0 1065.5,0 1065.5,0 1173.5,0 1173.5,0 1179.5,0 1185.5,-6 1185.5,-12 1185.5,-12 1185.5,-41 1185.5,-41 1185.5,-47 1179.5,-53 1173.5,-53\"/>\n<text text-anchor=\"start\" x=\"1081.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.019</text>\n<text text-anchor=\"start\" x=\"1067.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1626</text>\n<text text-anchor=\"start\" x=\"1061.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [16, 1610]</text>\n</g>\n<!-- 12&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>12&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1032.7434,-88.9777C1046.2217,-79.2713 1060.8715,-68.7213 1074.2291,-59.1018\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1076.2876,-61.9325 1082.357,-53.2485 1072.1969,-56.2522 1076.2876,-61.9325\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP39dVP5LOgB"
      },
      "source": [
        "Nous pouvons constater que les caractéristiques capital-gain, educationnal-num et age sont utilisés pour la classification. De la même manière (mais c'est plus concis), l'attribut feature_importances_ du classifieur retourne l'importance accordée à chacune des caractéristiques."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnxsT-a5LPGR",
        "outputId": "52af8c57-3f46-435d-a384-a772cafaec17"
      },
      "source": [
        "print(list(zip(cts_columns, clf.feature_importances_)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('age', 0.20444225321783052), ('fnlwgt', 0.0), ('educational-num', 0.2713516417000116), ('capital-gain', 0.5242061050821579), ('capital-loss', 0.0), ('hours-per-week', 0.0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0To2mP3oMpE2"
      },
      "source": [
        "Un hyperparamètre de notre arbre est *max_depth*, qui indique la profondeur maximale de l'arbre (dans notre cas, 3). Encore une fois, nous verrons dans la prochaine Formation Pratique 7 comment choisir les hyperparamètres.\n",
        "\n",
        "Les arbres de décisions sont des modèles relativement simples dont les performances sont généralement décevantes sur des problèmes un tant soit peu complexe. Cependant, il est possible d'entrainer plusieurs arbres différents, et de combiner leurs prédictions en utilisant une *forêt d'arbres de décision*. Ce modèle peut s'avérer très puissant et est parfois la meilleure méthode connue sur certains types de problèmes."
      ]
    }
  ]
}